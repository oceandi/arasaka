#!/usr/bin/env python3
"""
KAREL Network Dashboard - AI Model Entegrasyonu
DeepSeek R1 veya benzeri modeller iÃ§in entegrasyon modÃ¼lÃ¼
"""

import json
import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional
import requests
from datetime import datetime, timedelta
import os

class FiberArizaAI:
    def __init__(self, model_type: str = "deepseek-r1", api_key: Optional[str] = None):
        """
        AI Model entegrasyon sÄ±nÄ±fÄ±
        
        Args:
            model_type: KullanÄ±lacak model tipi (deepseek-r1, gpt-4, llama, vb.)
            api_key: API anahtarÄ± (gerekiyorsa)
        """
        self.model_type = model_type
        self.api_key = api_key or os.getenv(f"{model_type.upper()}_API_KEY")
        self.ml_data_path = "ml_data"
        
    def load_data(self) -> Dict[str, pd.DataFrame]:
        """ML verilerini yÃ¼kle"""
        data = {}
        
        # CSV dosyalarÄ±nÄ± yÃ¼kle
        for file in os.listdir(self.ml_data_path):
            if file.endswith('.csv'):
                table_name = file.replace('.csv', '')
                data[table_name] = pd.read_csv(f"{self.ml_data_path}/{file}")
                
        # JSON analizini yÃ¼kle
        with open(f"{self.ml_data_path}/database_analysis.json", 'r', encoding='utf-8') as f:
            data['analysis'] = json.load(f)
            
        return data
    
    def predict_future_failures(self, days_ahead: int = 7) -> List[Dict[str, Any]]:
        """
        Gelecekteki potansiyel arÄ±zalarÄ± tahmin et
        
        Args:
            days_ahead: KaÃ§ gÃ¼n sonrasÄ±nÄ± tahmin edeceÄŸiz
            
        Returns:
            Tahmin edilen arÄ±za listesi
        """
        data = self.load_data()
        df = data.get('fiber_ariza', pd.DataFrame())
        
        if len(df) == 0:
            return []
        
        predictions = []
        
        # Basit pattern analizi (gerÃ§ek ML modeli yerine)
        # TODO: GerÃ§ek ML modeli entegre edilecek
        
        # BÃ¶lgesel arÄ±za sÄ±klÄ±ÄŸÄ± analizi
        if 'bolge' in df.columns and 'ariza_baslangic' in df.columns:
            df['ariza_baslangic'] = pd.to_datetime(df['ariza_baslangic'], errors='coerce')
            
            # Son 30 gÃ¼nÃ¼n arÄ±zalarÄ±
            recent_date = df['ariza_baslangic'].max() - timedelta(days=30)
            recent_failures = df[df['ariza_baslangic'] > recent_date]
            
            # BÃ¶lge bazlÄ± risk skorlarÄ±
            risk_scores = recent_failures.groupby('bolge').size().to_dict()
            
            for bolge, count in risk_scores.items():
                if count > 5:  # YÃ¼ksek risk threshold
                    predictions.append({
                        'prediction_type': 'high_risk_area',
                        'location': bolge,
                        'risk_score': min(count / 5, 1.0),  # 0-1 arasÄ± normalize
                        'predicted_failures': int(count * 0.3),  # %30 tahmin
                        'timeframe_days': days_ahead,
                        'confidence': 0.75,
                        'reasoning': f"Son 30 gÃ¼nde {count} arÄ±za kaydÄ±"
                    })
        
        # KÃ¶k neden bazlÄ± tahmin
        if 'ariza_kok_neden' in df.columns:
            root_cause_freq = df['ariza_kok_neden'].value_counts().head(5)
            
            for cause, count in root_cause_freq.items():
                if pd.notna(cause) and count > 10:
                    predictions.append({
                        'prediction_type': 'recurring_issue',
                        'root_cause': cause,
                        'expected_occurrences': int(count * 0.1),
                        'timeframe_days': days_ahead,
                        'confidence': 0.65,
                        'prevention_suggestion': self._get_prevention_suggestion(cause)
                    })
        
        return predictions
    
    def _get_prevention_suggestion(self, root_cause: str) -> str:
        """KÃ¶k nedene gÃ¶re Ã¶nleme Ã¶nerisi"""
        suggestions = {
            'kablo kopmasÄ±': 'Kablo gÃ¼zergahlarÄ±nÄ±n dÃ¼zenli kontrolÃ¼ ve gÃ¼Ã§lendirme',
            'ek kutusu arÄ±zasÄ±': 'Ek kutularÄ±nÄ±n periyodik bakÄ±mÄ± ve yenilenmesi',
            'hafriyat': 'Hafriyat firmalarÄ±yla koordinasyon ve uyarÄ± sistemleri',
            'doÄŸal afet': 'Kritik noktalara yedekli altyapÄ± kurulumu',
            'ekipman arÄ±zasÄ±': 'Ekipman yaÅŸlandÄ±rma takibi ve proaktif deÄŸiÅŸim'
        }
        
        for key, suggestion in suggestions.items():
            if key.lower() in root_cause.lower():
                return suggestion
        
        return "DetaylÄ± analiz ve Ã¶nleyici bakÄ±m planÄ± Ã¶nerilir"
    
    def analyze_with_llm(self, prompt: str) -> str:
        """
        LLM kullanarak analiz yap
        
        Args:
            prompt: Analiz iÃ§in prompt
            
        Returns:
            Model yanÄ±tÄ±
        """
        if self.model_type == "deepseek-r1":
            return self._call_deepseek_r1(prompt)
        elif self.model_type == "gpt-4":
            return self._call_openai(prompt)
        else:
            return self._call_local_model(prompt)
    
    def _call_deepseek_r1(self, prompt: str) -> str:
        """DeepSeek R1 API Ã§aÄŸrÄ±sÄ±"""
        # TODO: GerÃ§ek API entegrasyonu
        # Åžimdilik simÃ¼le edilmiÅŸ yanÄ±t
        return f"""
# Fiber AltyapÄ± Analiz Raporu

## Mevcut Durum Analizi
VeritabanÄ±ndaki {self._get_total_records()} kayÄ±t Ã¼zerinden yapÄ±lan analizde:

### Kritik Bulgular:
1. **YÃ¼ksek Riskli BÃ¶lgeler**: Analiz sonucunda bazÄ± bÃ¶lgelerde arÄ±za yoÄŸunluÄŸu tespit edildi
2. **HAGS AÅŸÄ±m Durumu**: ArÄ±zalarÄ±n Ã¶nemli bir kÄ±smÄ±nda HAGS sÃ¼resi aÅŸÄ±lmÄ±ÅŸ
3. **Ã‡Ã¶zÃ¼m OranÄ±**: Mevcut Ã§Ã¶zÃ¼m oranÄ± iyileÅŸtirmeye aÃ§Ä±k

### Ã–neriler:
1. **Proaktif BakÄ±m**: Risk skorlarÄ± yÃ¼ksek bÃ¶lgelerde Ã¶nleyici bakÄ±m
2. **Kaynak Optimizasyonu**: ArÄ±za yoÄŸun bÃ¶lgelere ekip takviyesi
3. **AltyapÄ± GÃ¼Ã§lendirme**: SÄ±k arÄ±za veren gÃ¼zergahlarda kablo yenileme

## Tahminler:
Ã–nÃ¼mÃ¼zdeki 7 gÃ¼n iÃ§inde yaklaÅŸÄ±k 15-20 arÄ±za beklenmektedir.
"""
    
    def _call_openai(self, prompt: str) -> str:
        """OpenAI API Ã§aÄŸrÄ±sÄ±"""
        # TODO: OpenAI API entegrasyonu
        pass
    
    def _call_local_model(self, prompt: str) -> str:
        """Yerel model Ã§aÄŸrÄ±sÄ± (Ollama, vb.)"""
        # TODO: Ollama veya benzeri local model entegrasyonu
        pass
    
    def _get_total_records(self) -> int:
        """Toplam kayÄ±t sayÄ±sÄ±nÄ± al"""
        data = self.load_data()
        return len(data.get('fiber_ariza', pd.DataFrame()))
    
    def generate_dashboard_insights(self) -> Dict[str, Any]:
        """Dashboard iÃ§in AI destekli iÃ§gÃ¶rÃ¼ler Ã¼ret"""
        data = self.load_data()
        analysis = data.get('analysis', {})
        
        insights = {
            'generated_at': datetime.now().isoformat(),
            'summary': {},
            'alerts': [],
            'recommendations': [],
            'predictions': []
        }
        
        # Ã–zet istatistikler
        if 'fiber_ariza' in analysis.get('table_analysis', {}):
            fa = analysis['table_analysis']['fiber_ariza']
            sa = fa.get('special_analysis', {})
            
            insights['summary'] = {
                'total_records': fa['row_count'],
                'hags_violation_rate': sa.get('hags_stats', {}).get('hags_percentage', 0),
                'solution_rate': sa.get('solution_stats', {}).get('solution_rate', 0),
                'coordinate_coverage': sa.get('coordinate_stats', {}).get('coordinate_coverage', 0)
            }
            
            # UyarÄ±lar
            if insights['summary']['hags_violation_rate'] > 20:
                insights['alerts'].append({
                    'type': 'warning',
                    'message': f"HAGS aÅŸÄ±m oranÄ± %{insights['summary']['hags_violation_rate']:.1f} - Kritik seviyede!",
                    'priority': 'high'
                })
            
            if insights['summary']['solution_rate'] < 70:
                insights['alerts'].append({
                    'type': 'info',
                    'message': f"Ã‡Ã¶zÃ¼m oranÄ± %{insights['summary']['solution_rate']:.1f} - Ä°yileÅŸtirme gerekli",
                    'priority': 'medium'
                })
        
        # Tahminler
        insights['predictions'] = self.predict_future_failures(7)
        
        # Ã–neriler
        insights['recommendations'] = [
            {
                'title': 'Koordinat Verisi Tamamlama',
                'description': 'KoordinatsÄ±z arÄ±zalarÄ±n lokasyon bilgileri tamamlanmalÄ±',
                'impact': 'high',
                'effort': 'low'
            },
            {
                'title': 'HAGS SÃ¼re Optimizasyonu',
                'description': 'YÃ¼ksek HAGS aÅŸÄ±m oranÄ± iÃ§in sÃ¼reÃ§ iyileÅŸtirmesi',
                'impact': 'high',
                'effort': 'medium'
            }
        ]
        
        return insights
    
    def train_custom_model(self, model_path: str = "models/fiber_ariza_model.pkl"):
        """
        Ã–zel ML modeli eÄŸit
        
        Args:
            model_path: Modelin kaydedileceÄŸi yol
        """
        # TODO: GerÃ§ek ML model eÄŸitimi
        # - Random Forest, XGBoost, vb.
        # - Feature engineering
        # - Cross validation
        pass
    
    def export_training_data(self, output_file: str = "training_data.jsonl"):
        """
        Fine-tuning iÃ§in JSONL formatÄ±nda veri export et
        
        Args:
            output_file: Ã‡Ä±ktÄ± dosya adÄ±
        """
        data = self.load_data()
        df = data.get('fiber_ariza', pd.DataFrame())
        
        training_examples = []
        
        for _, row in df.iterrows():
            # Her arÄ±za kaydÄ±nÄ± soru-cevap formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼r
            example = {
                "messages": [
                    {
                        "role": "system",
                        "content": "Sen TÃ¼rkiye fiber optik altyapÄ± uzmanÄ±sÄ±n. ArÄ±za analizi ve Ã§Ã¶zÃ¼m Ã¶nerileri sunuyorsun."
                    },
                    {
                        "role": "user",
                        "content": f"BÃ¶lge: {row.get('bolge', 'Bilinmiyor')}, "
                                 f"Ä°l: {row.get('il', 'Bilinmiyor')}, "
                                 f"ArÄ±za nedeni: {row.get('ariza_kok_neden', 'Bilinmiyor')}. "
                                 f"Bu arÄ±za iÃ§in analiz ve Ã¶neri?"
                    },
                    {
                        "role": "assistant",
                        "content": f"ArÄ±za Analizi:\n"
                                 f"- Lokasyon: {row.get('lokasyon', 'BelirtilmemiÅŸ')}\n"
                                 f"- HAGS Durumu: {row.get('hags_asildi_mi', 'Bilinmiyor')}\n"
                                 f"- Ã‡Ã¶zÃ¼m Durumu: {row.get('kalici_cozum', 'Devam ediyor')}\n"
                                 f"- SÃ¼re: {row.get('ariza_suresi', 'HesaplanÄ±yor')}\n\n"
                                 f"Ã–neriler:\n"
                                 f"1. {self._get_prevention_suggestion(row.get('ariza_kok_neden', ''))}\n"
                                 f"2. Benzer arÄ±zalarÄ± Ã¶nlemek iÃ§in periyodik kontrol\n"
                                 f"3. {'Koordinat bilgisi eklenmeli' if pd.isna(row.get('kordinat_a')) else 'Lokasyon takibi aktif'}"
                    }
                ]
            }
            training_examples.append(example)
        
        # JSONL formatÄ±nda kaydet
        with open(f"{self.ml_data_path}/{output_file}", 'w', encoding='utf-8') as f:
            for example in training_examples:
                f.write(json.dumps(example, ensure_ascii=False) + '\n')
        
        print(f"âœ… {len(training_examples)} training Ã¶rneÄŸi {output_file} dosyasÄ±na kaydedildi")


# CLI kullanÄ±mÄ±
if __name__ == "__main__":
    print("ðŸ¤– KAREL Network Dashboard - AI Entegrasyonu")
    print("-" * 50)
    
    # AI modÃ¼lÃ¼ oluÅŸtur
    ai = FiberArizaAI(model_type="deepseek-r1")
    
    # Dashboard insights Ã¼ret
    print("\nðŸ“Š Dashboard Ä°Ã§gÃ¶rÃ¼leri Ãœretiliyor...")
    insights = ai.generate_dashboard_insights()
    
    print(f"\nðŸ“ˆ Ã–zet:")
    print(f"  - Toplam KayÄ±t: {insights['summary'].get('total_records', 0)}")
    print(f"  - HAGS AÅŸÄ±m OranÄ±: %{insights['summary'].get('hags_violation_rate', 0):.1f}")
    print(f"  - Ã‡Ã¶zÃ¼m OranÄ±: %{insights['summary'].get('solution_rate', 0):.1f}")
    
    # Tahminler
    print(f"\nðŸ”® Tahminler ({len(insights['predictions'])} adet):")
    for pred in insights['predictions'][:3]:
        print(f"  - {pred['prediction_type']}: {pred.get('location', pred.get('root_cause', 'N/A'))}")
        print(f"    Risk: %{pred.get('risk_score', pred.get('confidence', 0))*100:.0f}")
    
    # UyarÄ±lar
    if insights['alerts']:
        print(f"\nâš ï¸  UyarÄ±lar:")
        for alert in insights['alerts']:
            print(f"  - [{alert['priority'].upper()}] {alert['message']}")
    
    # Training data export
    print("\nðŸ“ Fine-tuning Verisi HazÄ±rlanÄ±yor...")
    ai.export_training_data()
    
    # SonuÃ§larÄ± kaydet
    with open('ml_data/ai_insights.json', 'w', encoding='utf-8') as f:
        json.dump(insights, f, ensure_ascii=False, indent=2)
    print("\nâœ… AI iÃ§gÃ¶rÃ¼leri ai_insights.json dosyasÄ±na kaydedildi")